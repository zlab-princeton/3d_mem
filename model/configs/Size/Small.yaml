name: "CustomDiT_Text_16Class_FlowMatching_1024x32_Small"

sampling_common: &sampling_common
  bounds: [-1.01, -1.01, -1.01, 1.01, 1.01, 1.01]
  octree_depth: 8        # callback will convert to octree_resolution=256
  num_chunks: 50000
  mc_level: 0.0

training:
  steps: 500000
  use_amp: true
  amp_type: "bf16"
  base_lr: 1e-4 # 1e-4
  gradient_clip_val: 1.0
  gradient_clip_algorithm: "norm"
  every_n_train_steps: 20000
  val_check_interval: 19999  # How often to run validation
  limit_val_batches: 4


dataset:
  target: hy3dshape.data.datamodule.UnifiedDataModule
  params:
    mode: "latent" # "raw" 
    batch_size: 128
    num_workers: 8
    max_dataset_size: 51200
    dataset_type: "objaverse_lvis"
    
    # Fill these in with your actual paths
    # dataset_folder: 
    # val_dataset_folder: 
    train_latent_folder: PATH/TO/TRAIN_LATENTS
    val_latent_folder:  PATH/TO/VAL_LATENTS


    train_csv_path: utils/lvis/top16/train.csv
    val_csv_path: utils/lvis/top16/val.csv
    conditioning_type: "text"
    snapshot_dir: ./splits/16-class

model:
  target: hy3dshape.models.diffusion.flow_matching_sit.Diffuser
  params:
    scale_by_std: true 
    z_scale_factor: 1.0
    torch_compile: true
    profile_with_events: false
    
    first_stage_config:
      target: hy3dshape.models.autoencoders.autoencoder.CustomShapeVAE
      params:
        model_depth: 24 # 12, 24
        model_dim: 1024 # 1024
        surface_size: 8192
        num_latents: 1024
        latent_dim: 32
        query_type: 'point'
        bottleneck: 'normalized'
        pretrained:
          ckpt_path: '/PATH/TO/point_vec1024x32_dim1024_depth24_sdf_nb/checkpoint-110.pth'
          ckpt_key: "model"
          strip_prefixes: ["module."]
          target_submodule: "autoencoder"

    cond_stage_config:
      target: hy3dshape.models.conditioner.MultiConditioner
      params:
        type: "text" # Must match dataset.conditioning_type
        # If type: "class", you would need to add:
        # num_classes: 100 
        text_embed_dim: 512
        p_uncond: 0.1

    denoiser_cfg:
      target: hy3dshape.models.denoisers.dit.DiTPlain
      params:
        in_channels: 32
        max_seq_len: 1024

        
        context_dim: 512 
        text_len: 77
        
        hidden_size: 512
        depth: 12
        num_heads: 16
        qk_norm: true
        use_attention_pooling: false
        use_pos_emb: false
        qk_norm_type: 'rms'
        num_moe_layers: 3
        num_experts: 4
        moe_top_k: 2 

    scheduler_cfg:
      transport:
        target: hy3dshape.models.diffusion.transport.create_transport
        params:
          path_type: Linear
          prediction: velocity
      sampler:
        target: hy3dshape.models.diffusion.transport.Sampler
        params: {}
        ode_params:
          sampling_method: euler
          num_steps: &num_steps 50


    optimizer_cfg:
      optimizer:
        target: torch.optim.AdamW
        params:
          fused: true
          betas: [0.9, 0.99]
          eps: 1.e-6
          weight_decay: 1.e-2
      scheduler:
        target: hy3dshape.utils.trainings.lr_scheduler.LambdaWarmUpCosineFactorScheduler
        params:
          warm_up_steps: 500
          f_start: 1.e-6
          f_min: 1.e-3
          f_max: 1.0
          
    pipeline_cfg:
      target: hy3dshape.pipelines.CustomFlowMatchingPipeline

callbacks:
  mesh_logger:
    target: hy3dshape.utils.trainings.mesh_log_callback.ConditionalMeshLogger
    params:
      step_frequency: 5000
      num_samples: 4
      # No more mean/std needed
      <<: *sampling_common
